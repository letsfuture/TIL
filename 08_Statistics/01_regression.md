# 회귀분석

## 1. 회귀분석 개요

- **회귀분석**
  - 인과관계로서 독립변수가 종속변수에 얼마큼 영향을 주는지 분석하는 것
  - **단순회귀분석:** 독립변수가 1개이며, 종속변수도 1개인 것
  - **다중회귀분석:** 만일 독립변수가 2개 이상인 경우의 회귀분석
- **회귀분석 전제 사항**
  1. **선형성:** 독립 변수의 변화에 따라 종속 변수도 일정 크기로 변함.
  2. **독립성:** 오차와 독립 변수의 값이 관련이 없음.
  3. **등분산성:** 독립 변수의 모든 값에 대해 오차들의 분산이 일정
  4. **비상관성:** 관측치의 오차들 사이에 상관관계가 없음.
  5. **정상성:** 오차가 정규분포를 따름.
- **상관분석**
  - 두 변수 사이의 원인과 결과가 아닌 서로 상관적 영향이 있는지 분석하는 것

<br>

## 2. 분포와 추론

- **표본공간(Sample space):** 어떤 실험을 할 때 나타날 수 있는 모든 결과들의 집합
- **사건(Event):** 표본공간에 있는 몇 개의 원소들로 이루어진 부분 집합

| 구분           | 분포명                                                       | 모듈명                                                       |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 이산 확률 분포 | - 이항 분포<br>- 베르누이 분포<br>- 기하 분포<br>- 다항 분포<br>- 포아송 분포 | - binomial(n, p[, size])<br>- binomial(n=1, p[, size])<br>- geometric(p[, size])<br>- multinomial(n, pvals[, size])<br>- poisson([lam, size]) |
| 연속 확률 분포 | - 균일분포<br>- 정규분포<br>- 지수분포<br>- t-분포<br>- 카이제곱분포<br>- F-분포 | - uniform([low, high, size])<br>- normal([loc, scale, size])<br>- exponential([scale, size])<br>- standard_t(df[, size])<br>- chisquare(df[, size])<br>- f(dfnum, dfden[, size]) |

- **통계적 추론(Statistical inference)**

  - 수집된 자료를 이용해 대상 집단(모집단)에 의해 의사결정을 하는 것을 의미
  - **점추정:** 모수가 특정한 값일 것이라고 추정하는 것
  - **구간추정:** 확률로 표현된 신뢰도 하에서 모수가 특정한 구간에 있을 것이라고 선언하는 것

- **가설검정(Hypothesis test)**

  - 모집단의 모수에 대한 어떤 가설을 설정한 뒤에 표본 관찰을 통해 그 가설의 채택 여부를 결정하는 분석 방법
  - **귀무가설(Null hypothesis, H0):** 검정하고자 하는 모수에 대한 가설이며, 버릴 것을 예상하는 가설
  - **대립가설(Alternative hypothesis, H1):** 연구자가 연구를 통해 입증되기를 기대하는 예상이나 주장을 대립가설로 내세움

- **유의수준과 유의확률**

  - **유의수준(α):** 귀무가설을 기각하게 되는 확률의 크기로, "귀무가설이 옳은데도 이를 기각하는 확률의 크기"로 정의
  - **기각역:** 귀무가설이 옳다는 전제하에서 구한 검정통계량의 분포에서 확률이 유의 수준 α인 부분을 의미
  - **가설 검정의 오류**
    - **제1종 오류(Type Ⅰ error):** 옳은 귀무가설을 기각하는 오류
    - **제2종 오류(Type Ⅱ error):** 옳지 않은 귀무가설을 채택하는 오류
  - **유의확률(p-value):** 제1종 오류를 발생할 확률을 의미하며, 신뢰수준이 95%일 경우 유의 확률이 유의수준(0.05)보다 작으면 귀무가설을 기각하는 대립가설을 채택하는 것을 의미

- **통계적 추론에서 모집단의 모수에 대한 검정 방법**

  - **모수적 방법(Parametric method)** 

    - 검정하고자 하는 모집단의 분포에 대한 가정이며, 그 가정하에서 검정통계량과 검정통계량의 분포를 유도해 검정을 실시

    - 관측된 자료를 이용해 구한 표본평균, 표본분산 등을 이용해 검정을 실시

  - **비모수적 방법(Non-parametric method)**

    - 관측된 데이터가 특정 분포를 가진다고 가정할 수 없는 경우 사용

    - 모집단 분포에 대한 가정을 하지 않고 검정을 실시

    - 부호검정(Sign test), 윌콕슨의 순위합검정(Rank sum test), 윌콕슨의 부호순위합검정(Wilcoxon signed rank test), 만-위트니의 U검정, 런검정(Run test), 스피어만의 순위상관계수 등 관측된 자료를 이용해 구한 표본평균, 표본분산 등을 이용해 검정을 실시

    - 관측값의 절대적인 크기에 의존하지 않는 관측값들의 순위(rank) 또는 두 관측값 차이의 부호(sign) 등을 이용해 검증

<br>

## 3. 상관분석

- **피어슨 상관계수:** <u>수치로 표시된 데이터간의 상관관계</u>를 확인하기 위해 사용

  | 범위        | 관계                    |
  | ----------- | ----------------------- |
  | -1.0≤r≤-0.7 | 매우 강한 음의 상관관계 |
  | -0.7<r≤-0.3 | 강한 음의 상관관계      |
  | -0.3<r≤-0.1 | 약한 음의 상관관계      |
  | -0.1≤r<0.1  | 상관관계 없음           |
  | 0.1<r≤0.3   | 약한 양의 상관관계      |
  | 0.3<r≤0.7   | 강한 양의 상관관계      |
  | 0.7<r≤1.0   | 매우 강한 양의 상관관계 |

- **스피어만 상관계수:** 분석하고자 하는 두 연속형 변수의 분포가 <u>심각하게 정규분포를 벗어난다거나 두 변수가 순위 척도 자료</u>일 때 사용

<br>

## 4. 단순 회귀분석

- `scipy.stats.linregress(x, y=None)` : 선형 최소 제곱 회귀식을 계산
- `numpy.polyfit(x, y, deg)` : 최소제곱 다항 회귀식을 계산

<br>

## 5. 포뮬러를 이용한 회귀식

- 선형회귀식을 구하기 위해 formula(포뮬러) 구문을 사용하여 통계 모형의 형식을 지정
- `ols()` 함수 또는 OLS 클래스의 `form_formula()`를 사용하면 포뮬러를 이용하여 다항 회귀식을 구할 수 있음.

| 기호 | 의미                                                         | 예        |
| ---- | ------------------------------------------------------------ | --------- |
| +    | 해당 변수를 포함                                             | +Z        |
| -    | 해당 변수를 제외                                             | -Z        |
| :    | 해당 변수들 사이의 상호작용을 포함                           | X:Z       |
| *    | 해당 변수와 그것들을 조합한 모든 상호작용들을 포함           | X*Z       |
| ^    | 예는 모든 상호작용을 최대 세 가지 방법으로 포함              | (X+Z+W)^3 |
| \|   | 수식으로 구성된 새 변수를 추가                               | \|(expr)  |
| -1   | 절편(intercept)을 삭제                                       | X-1       |
| .    | 데이터에서 종속변수를 제외한 모든 변수를 독립변수로 사용<br>.(점)은 R에서 사용할 수 있지만 파이썬에서는 사용할 수 없음 | Y ~.      |

<br>

## 6. 정규화 선형회귀

- 회귀 계수(Weight)에 대한 제약 조건을 추가해서 모형의 과적합(Overfitting)을 막는 방법
- OLS 클래스의 `fit_regularized()` 메소드를 사용해 회귀모형 계수를 구할 수 있음.
  - **Lasso:** 가중치의 절댓값의 합을 최소화
    - L1_wt가 1이면 순수 Lasso 모형
  - **Ridge:** 가충치들의 제곱합을 최소화
    - L1_wt가 0이면 순수 Ridge 모형
  - **Elastic Net:** 가중치의 절댓값의 합과 제곱합을 동시에 제약조건으로 가지는 모형
    - L1_wt가 0.5이면 순수 Elastic Net 모형
- **Ridge 모형과 Lasso 모형의 차이**
  - **Ridge 모형**은 가중치 계수를 모두 한꺼번에 축소시키는 반면, **Lasso 모형**은 일부 가중치 계수가 다른 가중치 계수에 비해 먼저 0으로 수렴하는 특성

<br>

## 7. 다중회귀분석

- **^(hat, 추정자):** 회귀식에서 ^(hat, 추정자)은 잔차를 의미하며 종속변수와 독립변수와의 관계를 밝히는 통계모형에서 모형에 의하여 추정된 종속변수의 값과 실제 관찰된 종속변수 값과의 차이를 의미

- **다중회귀식의 추정 방법**

  - **동시 입력법(전체 입력변수 투입)**

    모든 독립변수들을 포함하여 분석하는 방법으로 이를 통해 특정 독립변수의 영향력을 알 수 있음

  - **단계적 선택법(Step-wise)**

    다른 변수들이 회귀식에 존재할 때 종속변수에 영향력이 있는 변수들만을 회귀식에 포함시키는 방법

  - **후진 제거법**

    모든 독립변수를 모두 포함시킨 상태에서 기여도가 적은 변수부터 하나씩 제거
  
  - **전진 선택법**
  
    F 값에 가장 큰 기여를 하는 변수유의확률 p가 가장 작은 순서대로 하나씩 더해가는 방법
  
  - **제거법**
  
    독립변수없이 절편으로 구성된 모형을 만듦.
  
- **상관계수와 결정계수**

  - **상관계수(R; correlation coefficient):** 상관분석에서 상관관계의 정도를 나타내는 계수(-1<r<1)
  - **결정계수(R2; coefficient of determination, R-squared):** 상관계수를 제곱한 값(0<R^2<1)

- **수정된 결정계수**

  독립변수의 수가 늘어날수록 결정계수가 높아지는 단점이 있어 이를 보완하기 위해 도입

  <u>다중회귀분석에서는 결정계수가 아닌 수정된 결정계수를 언급해야 함</u>

- **회귀분석의 검증 항목 - 잔차의 독립성**

  - 회귀분석의 기본 가정 사항 중 잔차의 독립성이 있음
  - 잔차가 다른 잔차에 영향을 미치게 되는 경우를 자기상관이라고 하는데, 자기상관이 높으면 분석의 신뢰성을 잃게 됨.
  - 자기상관은 앞의 잔차항이 뒤의 잔차항에 영향을 미치는 경우로 주로 시계열 자료에서 많이 관찰됨.
  - **더빈 왓슨(Dubin-Watson)**의 통계량은 d라고 하며, 자기상관을 검증하는 통계량임.
  - 잔차의 독립성은 더빈 왓슨 값으로 판단하게 되는데 0에 가까울수록 양의 자기상관, 4에 가까울수록 음의 자기상관이 있다고 판단하며, 2에 가까울수록 자기 상관이 없다고 판단

- **회귀분석의 검증 항목 - 잔차의 정규성**

  - <u>잔차의 정규성은 그래프를 보고 판단</u>
  - 대각선을 중심으로 데이터들이 균일하게 분포되어 있어야 함.
  - 이상값이 많을수록 결정계수는 낮아지며, 그만큼 회귀식의 설명력 또한 낮아지게 됨.
  
- **다중공선성** 

  - 독립변수가 여러 개일 경우 그 변수들끼리 상관관계가 높을 경우 발생
  
  - **다중공선성 판단**
    
    - <u>독립변수들끼리의 상관계수가 90% 이상</u>
    
    - <u>VIF(Variance Inflation Factor; 분산 팽창 인자)가 10 이상으로 나올 경우</u>
      $$
      VIF = \frac{1}{1-R^2}
      $$
      
    
    - <u>공차한계(Tolerance)를 통해 판단</u>
    
      **공차한계:** 어떤 독립변수가 다른 독립변수들에 의해서 설명되지 않는 부분을 의미
  
  - VIF가 10 이상이거나 공차한계가 0.10 이하일 경우에는 공선성이 존재한다고 평가
  - 절대적인 기준은 없으므로 적절한 수준에서 판단해야 함.

<br>

## 8. 회귀모형 성능평가

- **scikit-learn의 모형 평가 방법**

  1. **예측 모형의 socre 메소드**

  2. **metrics 함수**

     분류, 회귀, 그리고 군집 등 예측 모형의 평가를 위한 함수들을 제공

  3. **scoring 매개변수**

     sklearn.model_selection 모듈의 cross_val_score() 함수 또는 GridSearchCV 클래스 등 교차 검증(cross-validation)을 사용하는 모형 평가 도구들은 내부적으로 scoring 매개변수를 이용해 모형 평가 규칙을 정의 

- **Regression 모형의 scoring 매개변수의 값과 평가함수**

| scoring 속성의 값          | metrics 모듈의 회귀모형 평가함수 | 참고      |
| -------------------------- | -------------------------------- | --------- |
| explained_variance         | metrics.explained_variance_score | 설명 분산 |
| neg_mean_absoulte_error    | metrics.mean_absolute_error      |           |
| neg_mean_squared_error     | metrics.mean_squared_error       |           |
| neg_mean_squared_log_error | metrics.mean_squared_log_error   |           |
| neg_median_absoulte_error  | metrics.median_absolute error    |           |
| r2                         | metrics.r2_score                 | 결정계수  |
